<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/png" href="images/seal_icon.png" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
    <td id="layout-menu">
        <div class="menu-category">Home</div>
        <div class="menu-item"><a href="index.html" >About&nbsp;me</a></div>
        <div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
        <div class="menu-item"><a href="students.html">Team</a></div>
        <div class="menu-item"><a href="awards.html">Awards</a></div>
        <div class="menu-item"><a href="talks.html">Talks</a></div>
        <div class="menu-item"><a href="services.html">Services</a></div>
        </td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
(* denotes equal contribution, &#8224; denotes corresponding author)
</div>

<h3>Recent Preprints</h3>
<ol reversed>

<li><p><b><a href="https://arxiv.org/abs/2511.11635" target="_blank">EduAgentQG: A Multi-Agent Workflow Framework for Personalized Question Generation</a></b> <br>
Rui Jia, Min Zhang, Fengrui Liu, Bo Jiang, Kun Kuang, <b>Zhongxiang Dai</b>.<br>
Preprint, 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2511.08873" target="_blank">UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models</a></b> <br>
Shouang Wei, Min Zhang, Xin Lin, Bo Jiang, Kun Kuang, <b>Zhongxiang Dai</b>.<br>
Preprint, 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2509.24696" target="_blank">T-POP: Test-Time Personalization with Online Preference Feedback</a></b> <br>
Zikun Qu, Min Zhang&#8224;, Mingze Kong, Xiang Li, Zhiwei Shang, Zhiyong Wang, Yikun Ban, Shuang Qiu, Yao Shu, <b>Zhongxiang Dai</b>&#8224;.<br>
Preprint, 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2509.24701" target="_blank">FedPOB: Sample-Efficient Federated Prompt Optimization via Bandits</a></b> <br>
Pingchen Lu*, Zhi Hong*, Zhiwei Shang, Zhiyong Wang, Yikun Ban, Yao Shu, Min Zhang, Shuang Qiu, <b>Zhongxiang Dai</b>&#8224;.<br>
Preprint, 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2502.00728" target="_blank">Meta-Prompt Optimization for LLM-Based Sequential Decision Making</a></b> <br>
Mingze Kong, Zhiyong Wang, Yao Shu, <b>Zhongxiang Dai</b>&#8224;.<br>
ICLR 2025 Workshop on Reasoning and Planning for Large Language Models.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2502.01118" target="_blank">Large Language Model-Enhanced Multi-Armed Bandits</a></b> <br>
Jiahang Sun*, Zhiyong Wang*, Runhan Yang*, Chenjun Xiao, John C.S. Lui, <b>Zhongxiang Dai</b>&#8224;.<br>
ICLR 2025 Workshop on Reasoning and Planning for Large Language Models.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2504.12016" target="_blank">Active Human Feedback Collection via Neural Contextual Dueling Bandits</a></b> <br>
Arun Verma, Xiaoqiang Lin, <b>Zhongxiang Dai</b>, Daniela Rus, Bryan Kian Hsiang Low.<br>
ICLR 2025, Workshop on on Bidirectional Human-AI Alignment.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2505.19241" target="_blank">ActiveDPO: Active Direct Preference Optimization for Sample-Efficient Alignment</a></b> <br>
Xiaoqiang Lin, Arun Verma, <b>Zhongxiang Dai</b>, Daniela Rus, See-Kiong Ng, Bryan Kian Hsiang Low.<br>
Preprint, 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2405.17346" target="_blank">Prompt Optimization with Human Feedback</a></b> <br>
Xiaoqiang Lin, <b>Zhongxiang Dai</b>&#8224;, Arun Verma, See-Kiong Ng, Patrick Jaillet and Kian Hsiang Low.<br>
ICML 2024 Workshop on Models of Human Feedback for AI Alignment. (Selected as Oral)
</p></li>
</ol>

<h3>Publications</h3>

<ol reversed>

<li><p><b><a href="https://arxiv.org/abs/2502.01085" target="_blank">Federated Linear Dueling Bandits</a></b> <br>
Xuhan Huang, Yan Hu, Zhiyan Li, Zhiyong Wang, <b>Zhongxiang Dai</b>&#8224;.<br>
AAAI 2026.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2505.11323" target="_blank">Convergence Rates of Constrained Expected Improvement</a></b> <br>
Haowei Wang, Jingyi Wang, <b>Zhongxiang Dai</b>, Nai-Yuan Chiang, Szu Hui Ng, Cosmin G. Petra.<br>
NeurIPS 2025 (Spotlight).
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2506.17252" target="_blank">Adaptive Sample Scheduling for Direct Preference Optimization</a></b> <br>
Zixuan Huang, Yikun Ban, Lean Fu, Xiaojie Li, <b>Zhongxiang Dai</b>, Jianxin Li, Deqing Wang.<br>
NeurIPS 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2310.00646" target="_blank">Source Attribution for Large Language Model-Generated Data</a></b> <br>
Jingtan Wang*, Xinyang Lu*, Zitong Zhao*, <b>Zhongxiang Dai</b>, Chuan-Sheng Foo, See-Kiong Ng and Kian Hsiang Low.<br>
ACL Findings 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2502.02079" target="_blank">Online Clustering of Dueling Bandits</a></b> <br>
Zhiyong Wang, Jiahang Sun, Mingze Kong, Jize Xie, Qinghua Hu, John C.S. Lui, <b>Zhongxiang Dai</b>&#8224;.<br>
ICML 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2502.01014" target="_blank">Refining Adaptive Zeroth-Order Optimization at Ease</a></b> <br>
Yao Shu, Qixin Zhang, Kun He, <b>Zhongxiang Dai</b>&#8224;.<br>
ICML 2025.
</p></li>

<li><p><b><a href="https://jmlr.org/papers/v26/22-0523.html" target="_blank">Adjusted Expected Improvement for Cumulative Regret Minimization in Noisy Bayesian Optimization</a></b> <br>
Shouri Hu, Haowei Wang, <b>Zhongxiang Dai</b>, Kian Hsiang Low and Szu Hui Ng.<br>
Journal of Machine Learning Research (JMLR), 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2407.17112" target="_blank">Neural Dueling Bandits: Principled Preference-Based Optimization with Non-Linear Reward Function</a></b> <br>
Arun Verma*, <b>Zhongxiang Dai</b>*&#8224;, Xiaoqiang Lin, Patrick Jaillet and Kian Hsiang Low.<br>
ICLR 2025.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2405.16122" target="_blank">Prompt Optimization with EASE? Efficient Ordering-aware Automated Selection of Exemplars</a></b> <br>
Zhaoxuan Wu*, Xiaoqiang Lin*, <b>Zhongxiang Dai</b>&#8224;, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet and Kian Hsiang Low.<br>
NeurIPS 2024.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2403.02993" target="_blank">Localized Zeroth-Order Prompt Optimization</a></b> <br>
Wenyang Hu*, Yao Shu*, Zongmin Yu, Zhaoxuan Wu, Xiaoqiang Lin, <b>Zhongxiang Dai</b>, See-Kiong Ng and Kian Hsiang Low.<br>
NeurIPS 2024 (Spotlight).
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2406.14473" target="_blank">Data-Centric AI in the Age of Large Language Models</a></b> <br>
Xinyi Xu, et al.<br>
EMNLP Findings 2024.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2310.02905" target="_blank">Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers</a></b> <br>
Xiaoqiang Lin*, Zhaoxuan Wu*, <b>Zhongxiang Dai</b>&#8224;, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet and Kian Hsiang Low.<br>
ICML 2024.
</p></li>

<li><p><b><a href="https://arxiv.org/abs/2403.07591" target="_blank">Robustifying and Boosting Training-Free Neural Architecture Search</a></b> <br>
Zhenfeng He, Yao Shu, <b>Zhongxiang Dai</b>, Bryan Kian Hsiang Low.<br>
ICLR 2024.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/quantum_bo.pdf" target="_blank">Quantum Bayesian Optimization</a></b> <br>
<b>Zhongxiang Dai</b>*, Gregory Kang Ruey Lau*, Arun Verma, Yao Shu, Kian Hsiang Low and Patrick Jaillet.<br>
NeurIPS 2023.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/batch_bo_replicable.pdf" target="_blank">Batch Bayesian Optimization For Replicable Experimental Design</a></b> <br>
<b>Zhongxiang Dai</b>, Quoc Phong Nguyen, Sebastian Shenghong Tay, Daisuke Urano, Richalynn Leong, Kian Hsiang Low and Patrick Jaillet.<br>
NeurIPS 2023.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/bandit_aux_feedback.pdf" target="_blank">Exploiting Correlated Auxiliary Feedback in Parameterized Bandits</a></b> <br>
Arun Verma, <b>Zhongxiang Dai</b>, Yao Shu and Kian Hsiang Low.<br>
NeurIPS 2023.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/neural_active_learning.pdf" target="_blank">Training-Free Neural Active Learning with Initialization-Robustness Guarantees</a></b> <br>
Apivich Hemachandra, <b>Zhongxiang Dai</b>&#8224;, Jasraj Singh, See-Kiong Ng and Kian Hsiang Low.<br>
ICML 2023.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/fed_neural_bandits.pdf" target="_blank">Federated Neural Bandits</a></b> <br>
<b>Zhongxiang Dai</b>, Yao Shu, Arun Verma, Flint Xiaofeng Fan, Kian Hsiang Low and Patrick Jaillet.<br>
ICLR 2023.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/zoo.pdf" target="_blank">Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation</a></b> <br>
Yao Shu*, <b>Zhongxiang Dai</b>*, Weicong Sng, Arun Verma, Patrick Jaillet and Kian Hsiang Low.<br>
ICLR 2023.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/aij2023.pdf" target="_blank">Recursive Reasoning-Based Training-Time Adversarial Machine Learning</a></b> <br>
Yizhou Chen, <b>Zhongxiang Dai</b>, Haibin Yu, Kian Hsiang Low and Teck-Hua Ho.<br>
Artificial Intelligence Journal, 2023.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/sto_bnts.pdf" target="_blank">Sample-Then-Optimize Batch Neural Thompson Sampling</a></b> <br>
<b>Zhongxiang Dai</b>, Yao Shu, Kian Hsiang Low and Patrick Jaillet.<br>
NeurIPS 2022.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/hnas.pdf" target="_blank">Unifying and Boosting Gradient-Based Training-Free Neural Architecture Search</a></b> <br>
Yao Shu, <b>Zhongxiang Dai</b>&#8224;, Zhaoxuan Wu and Kian Hsiang Low.<br>
NeurIPS 2022.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/bo_sdf.pdf" target="_blank">Bayesian Optimization under Stochastic Delayed Feedback</a></b> <br>
Arun Verma*, <b>Zhongxiang Dai</b>* and Kian Hsiang Low.<br>
ICML 2022.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/meta-BO.pdf" target="_blank">On Provably Robust Meta-Bayesian Optimization</a></b> <br>
<b>Zhongxiang Dai</b>, Yizhou Chen, Haibin Yu, Kian Hsiang Low and Patrick Jaillet.<br>
UAI 2022.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/neural_ensemble_search.pdf" target="_blank">Neural Ensemble Search via Bayesian Sampling</a></b> <br>
Yao Shu, Yizhou Chen, <b>Zhongxiang Dai</b> and Kian Hsiang Low.<br>
UAI 2022.
</p></li>

<li><p><b><a href="https://openreview.net/forum?id=v-v1cpNNK_v" target="_blank">NASI: Label- and Data-agnostic Neural Architecture Search at Initialization</a></b> <br>
Yao Shu, Shaofeng Cai, <b>Zhongxiang Dai</b>, Beng Chin Ooi and Kian Hsiang Low.<br>
ICLR 2022.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/dp_fbo.pdf" target="_blank">Differentially Private Federated Bayesian Optimization with Distributed Exploration</a></b> <br>
<b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet.<br>
NeurIPS 2021.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/CVaR_BO.pdf" target="_blank">Optimizing Conditional Value-At-Risk of Black-Box Functions</a></b> <br>
Quoc Phong Nguyen, <b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet.<br>
NeurIPS 2021.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/frl.pdf" target="_blank">Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee</a></b> <br>
Xiaofeng Fan, Yining Ma, <b>Zhongxiang Dai</b>, Wei Jing, Cheston Tan and Kian Hsiang Low.<br>
NeurIPS 2021.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/VaR_BO.pdf" target="_blank">Value-at-Risk Optimization with Gaussian Processes</a></b> <br>
Quoc Phong Nguyen, <b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet.<br>
ICML 2021.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/fbo.pdf" target="_blank">Federated Bayesian Optimization via Thompson Sampling</a></b> <br>
<b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet.<br>
NeurIPS 2020.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/R2_B2.pdf" target="_blank">R2-B2: Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games</a></b> <br>
<b>Zhongxiang Dai</b>, Yizhou Chen, Kian Hsiang Low, Patrick Jaillet and Teck-Hua Ho.<br>
ICML 2020.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/private_bo.pdf" target="_blank"> Private Outsourced Bayesian Optimization</a></b> <br>
Dmitrii Kharkovskii, <b>Zhongxiang Dai</b> and Kian Hsiang Low.<br>
ICML 2020.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/bo_bos.pdf" target="_blank">Bayesian Optimization Meets Bayesian Optimal Stopping</a></b> <br>
<b>Zhongxiang Dai</b>, Haibin Yu, Kian Hsiang Low, and Patrick Jaillet.<br>
ICML 2019.
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/uai2019.pdf" target="_blank">Bayesian Optimization with Binary Auxiliary Information</a></b> <br>
Yehong Zhang, <b>Zhongxiang Dai</b>, and Kian Hsiang Low.<br>
UAI 2019 (Plenary Talk).
</p></li>

<li><p><b><a href="https://daizhongxiang.github.io/papers/nips2019.pdf" target="_blank">Implicit Posterior Variational Inference for Deep Gaussian Processes</a></b> <br>
Haibin Yu*, Yizhou Chen*, <b>Zhongxiang Dai</b>, Kian Hsiang Low, and Patrick Jaillet.<br>
NeurIPS 2019 (Spotlight).
</p></li>

</ol>

</td>
</tr>
</table>
</body>
</html>